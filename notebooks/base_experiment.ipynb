{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from mini_transformers.data_load import ShakespeareDataset\n",
    "from mini_transformers.models.bigram_model import BigramModel\n",
    "from mini_transformers.models.embedding_model import (\n",
    "    SimpleEmbedding, HeadEmbedding, PositionHeadEmbedding, \n",
    "    MultiHeadedAttentionEmbedding, ResidualBlockAttentionEmbedding, GPT)\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "CONTEXT_LEN = 256\n",
    "ds = ShakespeareDataset(context_lenght=CONTEXT_LEN)\n",
    "\n",
    "# ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = ds.train_valid_subsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "QOecOECVP?rXA;:EGs3N,gFZBcCQ$USu'&EP&qcQcUCEPzBmdtI'\n",
      "bXpHHXr-wkTIdjekufuu3yb'HYMb3y-ZDHVqRTA;lJaNG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1337)\n",
    "# simple_text_generator = BigramModel(SimpleEmbedding(len(ds.vocabulary)))\n",
    "# head_text_generator = BigramModel(HeadEmbedding(len(ds.vocabulary), 100))\n",
    "# position_text_generator = BigramModel(PositionHeadEmbedding(len(ds.vocabulary), 100, context_len=CONTEXT_LEN))\n",
    "# attention_text_generator = BigramModel(SingleHeadedAttentionEmbedding(vocab_size=len(ds.vocabulary), n_embeds=100, head_size=100, context_len=CONTEXT_LEN))\n",
    "# attention_text_generator = BigramModel(MultiHeadedAttentionEmbedding(vocab_size=len(ds.vocabulary), n_embeds=100, n_heads=3, head_size=100, context_len=CONTEXT_LEN)).to('mps')\n",
    "# attention_text_generator = BigramModel(ResidualBlockAttentionEmbedding(vocab_size=len(ds.vocabulary), n_layers=6, n_embeds=100, n_heads=3, context_len=CONTEXT_LEN)).to('mps')\n",
    "attention_text_generator = BigramModel(GPT(vocab_size=len(ds.vocabulary), \n",
    "                                           n_layers=6, n_embeds=384, n_heads=6, \n",
    "                                           context_len=CONTEXT_LEN, dropout=0.2)).to('mps')\n",
    "text_generator = attention_text_generator\n",
    "# text_generator = position_text_generator\n",
    "gen_text = ds.vocabulary.decode(text_generator.generate().squeeze().tolist())\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(text_generator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 0.346: 100%|██████████| 15686/15686 [1:42:53<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "for xb, yb in (pbar := tqdm(train_loader)):\n",
    "    logits, loss = text_generator(xb.to('mps'), yb.to('mps'))\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    pbar.set_description(f'{loss = :.3f}')\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "PROSPERO:e that he did befre you not\n",
      "A better score in spite, for a Christian peace!\n",
      "What a sist rime, wound her that's bolted\n",
      "Still slaughter'd by Viencio, so speak and hour!\n",
      "he hath their tods: lether hear he make him lose; away. When.\n",
      "But with an unkindness of raves me?\n",
      "Nurse! Where is yond shall be here and supperfeCant\n",
      "Are speaks that we should be? We shout they seeds,\n",
      "Aid\n",
      "In that I see the very boot!\n",
      "From sure, as I sea--she hath a done of men,\n",
      "His young stands upon the way of heaven heart,\n",
      "Injury alives his wise; and when they must pace,--O,\n",
      "Piter your quarres, you wounds beauty is mistard.--\n",
      "She is to much my father's fair? What's the mater?\n",
      "Dost thou an arm mourn; I quarrely would love,\n",
      "And I feel out of the mount of heaven with ease?\n",
      "Ratcliff! a very farmer of life,\n",
      "In the meat\n"
     ]
    }
   ],
   "source": [
    "print(ds.vocabulary.decode(text_generator.generate(max_new_tokens=800, top_k=15).squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b = tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c = tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(f'{a = }')\n",
    "print(f'{b = }')\n",
    "print(f'{c = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, H)\n",
    "key = nn.Linear(C, head_size, bias=False) # (C, H)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k, q = key(x), query(x) # (B, T, H)\n",
    "v = value(x)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, H) x (B, H, T) = (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = wei @ v \n",
    "\n",
    "out.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
