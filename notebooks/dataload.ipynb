{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from mini_transformers.data_load import ShakespeareDataset\n",
    "from mini_transformers.models.bigram_model import BigramModel\n",
    "from mini_transformers.models.embedding_model import SimpleEmbedding, HeadEmbedding, PositionHeadEmbedding, SingleHeadedAttentionEmbedding, MultiHeadedAttentionEmbedding\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "CONTEXT_LEN = 8\n",
    "ds = ShakespeareDataset(context_lenght=CONTEXT_LEN)\n",
    "\n",
    "# ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = ds.train_valid_subsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y'Zbi IsjqExJrryIQCH-m\n",
      "ukANpzA:MFOZ3xqXjuyt$KDv?,haXyI3ryZbyyvYmPFWm,HAXjWxzE!r&jgkOA?3QfCYJyQyjMd:?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1337)\n",
    "# simple_text_generator = BigramModel(SimpleEmbedding(len(ds.vocabulary)))\n",
    "# head_text_generator = BigramModel(HeadEmbedding(len(ds.vocabulary), 100))\n",
    "# position_text_generator = BigramModel(PositionHeadEmbedding(len(ds.vocabulary), 100, context_len=CONTEXT_LEN))\n",
    "# attention_text_generator = BigramModel(SingleHeadedAttentionEmbedding(vocab_size=len(ds.vocabulary), n_embeds=100, head_size=100, context_len=CONTEXT_LEN))\n",
    "attention_text_generator = BigramModel(MultiHeadedAttentionEmbedding(vocab_size=len(ds.vocabulary), n_embeds=100, n_heads=3, head_size=100, context_len=CONTEXT_LEN))\n",
    "text_generator = attention_text_generator\n",
    "gen_text = ds.vocabulary.decode(text_generator.generate().squeeze().tolist())\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(text_generator.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 2.415: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 31371/31371 [04:11<00:00, 124.57it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "for xb, yb in (pbar := tqdm(train_loader)):\n",
    "    logits, loss = text_generator(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    pbar.set_description(f'{loss = :.3f}')\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRIOUCHANETONIUNES:\n",
      "Min: ans nen owe arvitherearee, sout ndoof tomrpeathietstterarbave domyou ftr fo\n"
     ]
    }
   ],
   "source": [
    "print(ds.vocabulary.decode(text_generator.generate().squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b = tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c = tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(f'{a = }')\n",
    "print(f'{b = }')\n",
    "print(f'{c = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, H)\n",
    "key = nn.Linear(C, head_size, bias=False) # (C, H)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k, q = key(x), query(x) # (B, T, H)\n",
    "v = value(x)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, H) x (B, H, T) = (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = wei @ v \n",
    "\n",
    "out.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_transformers",
   "language": "python",
   "name": "mini_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
